{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54907eb-07c2-4769-bf30-84c5374bc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bionet.biomodule import BioModule\n",
    "from bionet.modules.linear import FCNet\n",
    "from bionet.datasets import Datasets\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from bionet.modules.alexnetMini import AlexNetMini\n",
    "from bionet.modules.resnetMini import resnet20,resnet32,resnet44,resnet56,resnet110,resnet1202\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2af3b-eb8b-4bd6-ab75-5b1de32e61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, transform, epochs=2, optimizer=torch.optim.SGD, optimizer_args={'lr':1e-3}, purge=True, scale_grad=True, crystallize=True, verbose=False):\n",
    "    optimizer=optimizer(model.parameters(),**optimizer_args)\n",
    "    device = next(model.parameters())[0].device    \n",
    "    #with torch.autograd.detect_anomaly():    \n",
    "    models = []\n",
    "    for epoch in range(epochs):\n",
    "        correct=0\n",
    "        for idx, (sample, target) in enumerate(dataloader):\n",
    "            model.zero_grad()\n",
    "            sample, target= transform(sample.to(device)), target.to(device)\n",
    "            if len(sample.shape) == 3:                \n",
    "                sample = sample.unsqueeze(1)\n",
    "            output = model(sample)            \n",
    "            loss = nn.CrossEntropyLoss()(output, target)\n",
    "            loss.backward()\n",
    "            if scale_grad: model.scale_grad()\n",
    "            if purge: model.purge()\n",
    "            if crystallize: model.crystallize()\n",
    "            optimizer.step()\n",
    "            pred = output.argmax(dim=1, keepdim=True) \n",
    "            correct_batch = pred.eq(target.view_as(pred)).sum().item()\n",
    "            correct+=correct_batch\n",
    "            print(f'\\r{epoch:4d} {idx:4d} accuracy {correct_batch/float(len(sample)):6.4f} loss {loss.item():6.4f} ', end='')\n",
    "        if verbose: print(f'Accuracy for Epoch {epoch:3d} : {correct/dataloader.batch_size/len(dataloader): 6.4f} ')\n",
    "        if epoch in [0,50,100,200]:\n",
    "            models.append({\"epoch\":epoch, \"state_dict\":model.state_dict()})\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13c8e2-e8d7-4828-a06b-85eba0989747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_resnet(model_name, num_channels, num_classes):\n",
    "    if '1202' in model_name:\n",
    "        return resnet1202(num_channels, num_classes)\n",
    "    elif '32' in model_name:\n",
    "        return resnet32(num_channels, num_classes)\n",
    "    elif '44' in model_name:\n",
    "        return resnet44(num_channels, num_classes)\n",
    "    elif '56' in model_name:\n",
    "        return resnet56(num_channels, num_classes)\n",
    "    elif '110' in model_name:\n",
    "        return resnet110(num_channels, num_classes)\n",
    "    else :\n",
    "        return resnet20(num_channels, num_classes)\n",
    "\n",
    "def run(model_class =  'FCNet', model_args = {'in_feats':784, 'shapes':[1000], 'num_classes':10}, \n",
    "        optimizer = 'SGD', optimizer_args= {'lr':1e-3}, grad_scale=0.09, batch_size=100, vbatch_size=1000,\n",
    "        dampening_factor = 0.6,fold=5, crystal_thresh=4.5e-5, purge_distance=8.0, accum_neurons=2,\n",
    "       epochs=201, dataset_name='CIFAR100', purge=True, scale_grad=True, crystallize=False, verbose=False):\n",
    "    converter = BioModule.get_convert_to_bionet_converter(grad_scale=grad_scale, dampening_factor=dampening_factor, crystal_thresh=crystal_thresh,purge_distance=purge_distance, accum_neurons=accum_neurons)\n",
    "    \n",
    "    str_model_class = model_class\n",
    "    str_optimizer = optimizer\n",
    "    \n",
    "    optimizer = torch.optim.SGD\n",
    "    num_channels = 3 if dataset_name.upper() != 'MNIST' else 1\n",
    "    num_classes = 100 if dataset_name.upper()[-3:] == '100' else 10\n",
    "    \n",
    "    if model_class == \"FCNet\":\n",
    "        \n",
    "        model_class = FCNet\n",
    "        model_args = {'in_feats':3*32*32, 'shapes':[3000,3000], 'num_classes':100}\n",
    "    elif 'resnet' in model_class:\n",
    "        model_class, model_args =  eval_resnet(model_class, num_channels, num_classes)\n",
    "    else:\n",
    "        model_args = {\"num_classes\":num_classes, \"num_chans\":num_channels, \"target\":dataset_name.upper()}\n",
    "        model_class = AlexNetMini\n",
    "    \n",
    "    model_class = converter(model_class)\n",
    "    dataset = Datasets(dataset_name)\n",
    "    transform=nn.Sequential(\n",
    "            transforms.Normalize(**dataset.normalization)\n",
    "            )\n",
    "    \n",
    "    model = model_class(**model_args).cuda()\n",
    "    dataset.train()\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, pin_memory=True, num_workers=0, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    models = train(model, dataloader, transform, epochs=epochs, optimizer=optimizer, optimizer_args=optimizer_args, \n",
    "          purge=purge, scale_grad=scale_grad, crystallize=crystallize, verbose=verbose)\n",
    "\n",
    "    options = {'model_class' :  str_model_class, 'model_args' : model_args, 'optimizer' :str_optimizer, 'optimizer_args': optimizer_args, 'grad_scale':grad_scale, \n",
    "           'batch_size':batch_size, 'vbatch_size':vbatch_size,'dampening_factor':dampening_factor,'fold':fold, 'crystal_thresh':crystal_thresh, 'purge_distance':purge_distance, 'accum_neurons':accum_neurons,'epochs':epochs, \n",
    "           'dataset_name':dataset_name, 'purge':purge, 'scale_grad':scale_grad, 'crystallize':crystallize, 'verbose':verbose}\n",
    "    if verbose:\n",
    "        print(np.mean(accs), np.std(accs))\n",
    "        plt.plot(accs)\n",
    "        plt.show()\n",
    "        plt.plot(losses)\n",
    "        plt.show()\n",
    "    return {'model':str_model_class, 'options':options, 'models':models }\n",
    "\n",
    "combinations = [\n",
    "    [False, False], \n",
    "    [True, False],  \n",
    "    [False, True], \n",
    "    [True, True], \n",
    "]\n",
    "nets = ['FCNet', 'AlexNetMini', 'resnet20', 'resnet56']\n",
    "accums = [0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6ed34-86b5-4e93-b6e9-7af9308dbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "#result_list = []\n",
    "i=0\n",
    "num_runs = len(combinations)*len(nets)*len(accums)\n",
    "\n",
    "\n",
    "def hms_from_seconds(time_el):\n",
    "    h_el = int(time_el//3600)\n",
    "    m_el = int((time_el-3600*h_el)//60)\n",
    "    s_el = int(time_el-3600*h_el-m_el*60)\n",
    "    return h_el, m_el, s_el\n",
    "t0 = time()\n",
    "for net in nets:\n",
    "    for accum in accums:\n",
    "        for combination in combinations:\n",
    "            t1 = time()\n",
    "            time_el = int(t1-t0)\n",
    "            h_el, m_el, s_el = hms_from_seconds(time_el)\n",
    "            approx_time_to_go = 0 if i==0 else (time_el/i)*num_runs\n",
    "            h_to, m_to, s_to = hms_from_seconds(approx_time_to_go)\n",
    "            purge, scale_grad = combination\n",
    "            print(f\"Working on Combination #{i:4d} of {num_runs:4d}: net: {net}, accum: {accum} purge: {purge}, scale_grad: {scale_grad} - time elapsed {h_el:2d}h {m_el:2d}min {s_el:2d}s - {h_to:2d}h {m_to:2d}min {s_to:2d} to go\" )\n",
    "            res = run(model_class = net, accum_neurons=accum, purge= purge, scale_grad=scale_grad)\n",
    "            result = {'result':res, 'options':{'net':net, 'accum':accum, 'combination':combination, 'purge':purge, 'scale_grad':scale_grad}}\n",
    "            pkl.dump(result, open(f'experiments/tmp_res_v3_{net}_{accum}_{purge}_{scale_grad}.pkl','wb'))\n",
    "            i+=1\n",
    "            print()       \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
